stages:
  #  - lint
  - build
  - push
  - deploy
  - cleanup

# add the lint stage to verify the code structure and syntax. This will abort the pipeline if there are problems

    
# this lint stage is non-blocking and will not abort, but just report the INFO to the gitlab console


    
build:
  stage: build
  script:
    # this one is for running Dockerfile which is python wrapper method (and it ai parallelized now). It is 
    # a manual script running of the python files natively in parallel (not using multi-threading python class)
    # using a file range(array list) function
    #- docker build -t $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE:latest .
    
    # this one is for running Dockerfile_python_mod_NO_but_serial, the python modularization setup without parallelization
    #- docker build --file Dockerfile_python_mod_NO_but_serial -t $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE:latest .

    # this one is for running Dockerfile_python_mod_multi_threaded, modularization with multi-threading
    #- docker build --file Dockerfile_python_mod_multi_threaded -t $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE:latest .
  
    # this one is for running Dockerfile_python_mod_multi_processing, modularization with mutli-processing
    - docker build --file Dockerfile_python_mod_multi_processing -t $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE:latest .


push:
  stage: push
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker push $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA
    - docker push $CI_REGISTRY_IMAGE:latest


      # default instance_type is t2.micro. Test out a t3.small for performance installation issues.   
      # 30 processes(desired_count)  x chunk_size=2 → 60 EC2 instances total so set max and min count to 60 (example)   
deploy:
  stage: deploy
  timeout: 4h
  variables:
    PID_JSON_DUMPS: "false"  
    # this is a gating env VAR for module2 if I need to disable the process level resurrection candidate
    # or ghost json artifact files during hyper-scalling
 
    ##### Synthetic thread failures in install_tomcat ########
    FORCE_TOMCAT_FAIL: "false"  # ← Inject synthetic failure for testing (futures crash). The synthetic futures crash code is in instalL_tomcat. Use "1" or "true" to inject and "false" or "0" to not inject. This one is right before the for idx.  These FORCE_TOMCAT crashes do not exercise actual module2c scanning code. See below for that ENV variable.

    FORCE_TOMCAT_FAIL_IDX1: "false"

    FORCE_TOMCAT_FAIL_POSTINSTALL: "false"

    FORCE_TOMCAT_FAIL_PRE_SSH: "false"

    INJECT_SYNTHETIC_GHOST1: "false"  # Inject a synthetic ghost into the aggregate_gold_ips list in main() in module 2. Module2b will pick this up in aggregate_ghost_summary.log  and find that there is a ghost that needs to be analyzed in the logs. 1.1.1.1

    INJECT_SYNTHETIC_GHOST2: "false"  # 1.1.1.2
    INJECT_SYNTHETIC_GHOST3: "false"  # 1.1.1.3
    INJECT_SYNTHETIC_GHOST4: "false"  # 1.1.1.4
    INJECT_SYNTHETIC_GHOST5: "false"  # 1.1.1.5
    INJECT_SYNTHETIC_GHOST6: "false"  # 1.1.1.6
    INJECT_SYNTHETIC_GHOST7: "false"  # 1.1.1.7
    INJECT_SYNTHETIC_GHOST8: "false"  # 1.1.1.8
    INJECT_SYNTHETIC_GHOST9: "false"  # 1.1.1.9
    INJECT_SYNTHETIC_GHOST10: "false"  # 1.1.1.10





    FORCE_TOMCAT_FAIL_POSTINSTALL_REAL_TAG: "false"  # post install futures crash with real tagging of module2c. This actually uses the
      # post gitlab console logs sanning of module2c to determine if there is a futures crash that had all commands executed 
      # successfully. In this case an additional tag has to be added that indicates that installation is successful.
      # The gatekeeper will bypass resurrecting this thread.


    FORCE_TOMCAT_FAIL_IDX1_REAL_TAG: "false"   # this futures crash will hit the module2c scan but an additional tag should not be 
      # inserted. The gatekeeper will try to resurrect this thread.      

    FORCE_TOMCAT_FAIL_HYBRID_FUTURES_CRASH: "false"  # this uses the pid which is somewhat deterministic in a 16 node test to 
      # activate half of the processes with a futures crash after the first command and the other half of the processes with a futures
      # crash after all the commands have succeeded. This tests the gatekeeper stats code implemenented in module2d. This 
      # activates FORCE_TOMCAT_FAIL_POSTINSTALL_REAL_TAG crash for half of the processes and activates 
      # FORCE_TOMCAT_FAIL_IDX1_REAL_TAG for the other half of the processes. If this is used with the 512 node test only a few of 
      # the processes will get futures crashes which is also a good partial test. This is true with any test that uses > 16 nodes.
      # NOTE: If setting HYBRID above to true, best to set the other 2 (IDX1 and POSTINSTALL) to false.


    # DEPRECATED:
    #INJECT_PROCESS_GHOSTS: "false" # this is injection of ghosts at the process chunk level which main() will then pass to all the
      # downstream modules like tomcat_worker resurrection_monitor_patch8 threaded_install and install_tomcat so that detect_ghosts
      # helper function can be tested. This is a more realistic ghost injection. This does not work because it requires a synthetic
      # InstanceId as well for downstream code, and that synthetic InstanceId causes a futures crash (install_failed) instead of a
      # ghost.  The code for this has been commented out.   Use the flag below
      
    INJECT_POST_THREAD_GHOSTS: "false"  # this injection is in tomcat_worker between the process_registry run_test call to 
      # threaded_install which establishes the process_registry for the process (seen_ips) and the call to 
      # resurrection_monitor_patch8. The instance_info variable is mutated in between the two with the ghost injection. This 
      # creates delta between seen_ips and golden ips which are missing_ips or ghosts, as evalluated by the helper fuction 
      # detect_ghosts. Once this happens detect_ghosts prints the PID and the ghost ip and module2b picks this up in the 
      # gitlab console log scan, and it can then create the aggregate_ghost_deteail.json ghost entry which will then be 
      # synthetically modified to registry_entry format in module2d so that it can be processed by the gatekeeper.

    INJECT_POST_THREAD_GHOSTS_REAL_PUBLIC_IPS: "true"  # this injection is similar to INJECT_POST_THREAD_GHOSTS but allows for real node public ips (and private ips)
      # to be used. The code is very similar to the INJECT_POST_THREAD_GHOSTS. The injections are made in tomcat_worker at the process level (1 ghost ip
      # per process), written to disk (1 ip per json file) and then main() retrieves the ip addresses from disk and assimilates and aggregates them from the process 
      # level into the aggregate_gold_ips which is then used in the downstream modules (synthetic ghost registry creation, etc)
      # The public ip addresses are added to a block very early in main() of module2 prior to the call by multiprocessing.Pool to tomcat_worker. 
      # This ensures that the addresses are available to each process call to tomcat_worker and they can be popped from the list one by one, one per process
      # and incorporated into the process registry for that pid. This has been tested and works very well.


    INJECT_FAKE_INSTANCE_ID: "false"
    FAKE_INSTANCE_ID: "FAKE_INSTANCE_ID"
      # This is to inject a fake instance_id into the modules2e and 2f for conditional logic testing in those modules for resurrection and tagging code.
      # The instance_id above is a real life AWS instance_id
      # Note that the FAKE_INSTANCE_ID format has to be "correct". Best to use a recently retired node instance_id. These are AWS cached after a while and
      # need to be refreshed with a more recent one periodically.
      # For example, i-1234567890abcdef0 looks to be correct format but AWS API will return InvalidInstanceID.Malformed
      # The i-033f7957281756224 is a recently retired node real instance_id and this worked prior to AWS caching it as no longer valid.
      # While it worked it behaved in the code as a real instance_id (during reboot loop the watchdog had to timeout eventually since it is no longer atached
      # to a node).  When it stopped working after AWS caching, AWS API flagged it as InvalidInstanceID.NotFound and this tests a different part of the python
      # code.
      # Sample instance_ids from retired nodes: 
      #i-04db5334416589234
      #i-0e171a13c0da524e9
      #i-09d00eb1f30eaeb85
      #i-05fc3ce4109e796a9
      #i-0195d85406c9c8f2c
      #i-0750539f179a9a9de
      #i-06f22e9fa5d3425aa
      #i-0174c6e94e77bdfbd
      #i-0455f491c18dafb6e
      #i-08075356b54d333bb
      #i-0d1218e706c833bbe
      #i-00026dd675257fdc3
      #i-08189c48ff63f7065
      #i-090f41ce4e6b4f5f3
      #i-08f1057b9a79cfae5
      #i-07ab1e5de09a2e8f7

  before_script:
    - echo 'AWS_ACCESS_KEY_ID='${AWS_ACCESS_KEY_ID} >> .env
    - echo 'AWS_SECRET_ACCESS_KEY='${AWS_SECRET_ACCESS_KEY} >> .env
    - echo 'region_name=us-east-1' >> .env
    - echo 'image_id=ami-0f9de6e2d2f067fca' >> .env
    - echo 'instance_type=t2.micro' >> .env
    - echo 'key_name=generic_keypair_for_python_testing' >> .env
    - echo 'min_count=16' >> .env
    - echo 'max_count=16' >> .env
    - echo 'AWS_PEM_KEY='${AWS_PEM_KEY} >> .env
    - echo 'DB_USERNAME='${DB_USERNAME} >> .env
    - echo 'DB_PASSWORD='${DB_PASSWORD} >> .env
    
    - echo 'PID_JSON_DUMPS='${PID_JSON_DUMPS} >> .env  # see above. Gating for the json ghost and res candidate files.  
    
    - echo 'FORCE_TOMCAT_FAIL='${FORCE_TOMCAT_FAIL} >> .env # This is to inject a futures crash in install_tomcat
    - echo 'FORCE_TOMCAT_FAIL_IDX1='${FORCE_TOMCAT_FAIL_IDX1} >> .env # futures crash after first command executes
    - echo 'FORCE_TOMCAT_FAIL_POSTINSTALL='${FORCE_TOMCAT_FAIL_POSTINSTALL} >> .env  # futures crash after installation
    - echo 'FORCE_TOMCAT_FAIL_PRE_SSH='${FORCE_TOMCAT_FAIL_PRE_SSH} >> .env  # futures crash before SSH initiated
    
    - echo 'INJECT_SYNTHETIC_GHOST1='${INJECT_SYNTHETIC_GHOST1} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST2='${INJECT_SYNTHETIC_GHOST2} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST3='${INJECT_SYNTHETIC_GHOST3} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST4='${INJECT_SYNTHETIC_GHOST4} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST5='${INJECT_SYNTHETIC_GHOST5} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST6='${INJECT_SYNTHETIC_GHOST6} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST7='${INJECT_SYNTHETIC_GHOST7} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST8='${INJECT_SYNTHETIC_GHOST8} >> .env  # inject synthetic ghost into aggregate_gold_ips
    
    - echo 'INJECT_SYNTHETIC_GHOST9='${INJECT_SYNTHETIC_GHOST9} >> .env  # inject synthetic ghost into aggregate_gold_ips
    
    - echo 'INJECT_SYNTHETIC_GHOST10='${INJECT_SYNTHETIC_GHOST10} >> .env  # inject synthetic ghost into aggregate_gold_ips

  
    
    - echo 'FORCE_TOMCAT_FAIL_POSTINSTALL_REAL_TAG='${FORCE_TOMCAT_FAIL_POSTINSTALL_REAL_TAG} >> .env  # futures crash after installation with real tagging using module2c

    - echo 'FORCE_TOMCAT_FAIL_IDX1_REAL_TAG='${FORCE_TOMCAT_FAIL_IDX1_REAL_TAG} >> .env  # futures crash after first command and module2c will not insert the addtional tag


    - echo 'FORCE_TOMCAT_FAIL_HYBRID_FUTURES_CRASH='${FORCE_TOMCAT_FAIL_HYBRID_FUTURES_CRASH} >> .env  # futures crash with mix of FORCE_TOMCAT_FAIL_POSTINSTALL_REAL_TAG in half of the processes, and FORCE_TOMCAT_FAIL_IDX1_REAL_TAG in the other half of the processes.



    - echo 'INJECT_PROCESS_GHOSTS='${INJECT_PROCESS_GHOSTS} >> .env  # inject synthetic ghost at the process chunk level. This code does not work well as noted above.


    - echo 'INJECT_POST_THREAD_GHOSTS='${INJECT_POST_THREAD_GHOSTS} >> .env  # inject synthetic ghost at the process level in tomcat_worker between the call to run_test/threaded_install for the process_registry AND the call to the resurrection_monitor_patch8. Mutate the aggregate_gold_ips in main()

    - echo 'INJECT_POST_THREAD_GHOSTS_REAL_PUBLIC_IPS='${INJECT_POST_THREAD_GHOSTS_REAL_PUBLIC_IPS} >> .env # inject real node public ips as ghosts at the process level in tomcat_worker between the call to run_test/threaded_install for the process_registry AND the call to the resurrection_monitor_patch8. Mutate teh aggregate_gold_ips in main() 


    - echo 'INJECT_FAKE_INSTANCE_ID='${INJECT_FAKE_INSTANCE_ID} >> .env # this injects fake instance_id for module2e and 2f reboot and resurrection testing Phase3
    - echo 'FAKE_INSTANCE_ID='${FAKE_INSTANCE_ID} >> .env 


       
      ## NOTE: To turn off dumps in specific pipelines or environments:Go to **Settings > CI/CD > Variables in the project
      ## Define `PID_JSON_DUMPS` with value `false` (masked/protected as needed).
      ## This value will override the one above in this file. 


      #      # use this for most of the Dockerfiles. The multiprocessing Dockerfile is collecting logs from the container for
      #      # benchmarking so use the one below for the multiprocessing Dockerfile    
      #  script:
      #    - docker run --rm --env-file .env $CI_REGISTRY_IMAGE:latest
      #  allow_failure: true
      #  # this will keep the pipeline going to cleanup stage even if the above python script  fails
      #  only:
      #    - main
      #




      # use this one for the multiprocessing Dockerfile. This mounts to the WORKDIR on the container so that
      # the gitlab pipeline can get the artifact from the $CI_PROJECT_DIR of the gitlab repo
      # The artifact path is specified below relative to the gitlab project directory
      # Refer to teh python module2 to see the per process logging setup to benchmark the multi-threading operations
      # in each process
      #
  script:
    - mkdir -p logs
    - mkdir -p logs/statistics  # this is required so that the statistics directory has gitlab-runner as owner.
    #- docker run --rm --env-file .env -v $CI_PROJECT_DIR/logs:/aws_EC2/logs $CI_REGISTRY_IMAGE:latest
    # add the tee to get all the gitlab console output into a log file in the gitlab artfacts:
    - docker run --rm --env-file .env -v $CI_PROJECT_DIR/logs:/aws_EC2/logs $CI_REGISTRY_IMAGE:latest | tee logs/gitlab_full_run.log  
    - echo "Contents of logs directory after container run:"
    - ls -l logs/
    
    - echo "Contents of logs/statistics directory after container run:"
    - ls -l logs/statistics/    
    
    - echo "Last 10 lines of MAIN logs:"
    - cat logs/main_*.log | tail -10

    - |
      for f in logs/benchmark_[0-9]*.log; do
      # bad bug creating duplicated entires from benchmark_combined_runtime.log in patch7 in benchmark_combined.log
      #for f in logs/benchmark_*.log; do
        echo "===== $f =====" >> logs/benchmark_combined.log
        cat "$f" >> logs/benchmark_combined.log
        echo "" >> logs/benchmark_combined.log
      done

  after_script:
    - sudo chown -R $(id -u):$(id -g) logs/statistics || true
  


  artifacts:
    paths:
      - logs/
      - logs/main_*.log  # top elve orchestration level stats for entire execution
      - logs/benchmark_*.log  # process level orchestration level stats logs 
      - logs/benchmark_combined.log  # this is the orchestration level logging of all the benchmark_*.logs (process level stats). This is created post execution in gitlab-ci.yml (seea above)

      - logs/benchmark_combined_runtime.log  # this is the python run time created benchmark_combined stats log created from the benchmark_*.log pid logs that are created during run time.  
      
      - logs/benchmark_ips_artifact.log  # this a list of benchmark ips from the threads in the benchmark_combined_runtime.log

      - logs/total_registry_ips_artifact.log  # stats created from the final_aggregate_execution_run_registry.json registry. THese are the actual registry entries, not stats. Same for the next 3 logs as well.
      - logs/missing_registry_ips_artifact.log
      - logs/successful_registry_ips_artifact.log
      - logs/failed_registry_ips_artifact.log
      
      - logs/patch7_summary_*.log # this is for the per process logging in resurrection_monitor_patch7c. This is completely separate from the orchestration level logging and this is used for forensics and debugging.
      
        # these are process level logs from the resurrection_montior_patch7c(). These are actual registry entries for resurrection candidates for phase3 implementation. Ghosts are missing when compared to GOLD standard and do not have standard failure tags  
      - logs/resurrection_candidates_registry_*.json
      - logs/resurrection_ghost_missing_*.json
      - logs/resurrection_untraceable_registry_entries_*.json  
     
      # resurrection_monitor pid based snapshot for all registry values. This has been replaced with final_aggregate_execution_run_registry.json
      #- logs/resurrection_process_registry_snapshot_*.json
      
      # write-to-disk aggregator json files. The log files above are derived from these. This has all registry values for the
      # entire execution run. This replaces the snapshot json log above that was formerly done in resurrection_monitor
      # This log below is done in main()
      - logs/final_aggregate_execution_run_registry.json
      
      # per process registry logs from tomcat_worker(). These are used to create the final_registry and summary and these are then used to create the aggregate registry for the execution run : logs/final_aggregate_execution_run_registry.json
      - logs/process_registry_*.json  
        
      # This is the log file for the GOLD aggreagate IP EC2 list from the AWS control plane operations. This will be used for ghost detection at aggregate level. This is derived from "chunks" the pre-processing  of the IPs for the multi-processing engine.
      - logs/aggregate_chunk_gold_ip_list.log  
       
      # This is an aggregate level ghost list of ips from the GOLD standard comparison list above

      - logs/aggregate_ghost_summary.log  

      # These are the complete gitlab console logs from the docker run tee above. These will be used for post ghost analysis tagging.
      - logs/gitlab_full_run.log    
   
      # module2b post ghost analysis artifact log file
      - logs/aggregate_ghost_detail.json 

      # module2c post aggregate registry analysis artifact log file
      - logs/final_aggregate_execution_run_registry_module2c.json

      # module2d post aggregate registry that has been processed by the resurrection_gatekeeper
      - logs/final_aggregate_execution_run_registry_module2d.json

      # module2d aggregate_ghost_detail that has been transformed into synthetic registry (for res gatekeeper processing)
      - logs/aggregate_ghost_detail_synthetic_registry.json

      # module2d post aggregate ghost detail that has been processed by the resurrection_gatekeeper    
      - logs/aggregate_ghost_detail_module2d.json

      # module2d consolildated aggregate_ghost_detail_module2d.jsn + final_aggregate_execution_run_registry_module2d.json for
      # Phase3 resurrection and requeing code
      - logs/resurrection_gatekeeper_final_registry_module2d.json   


      # These logs are for the process level synthetic ghost injection and are not normally seen. Only seen when the
      # INJECT_POST_THREAD_GHOST ENV variable is enabled
      - logs/synthetic_process_ghost_ip_pid_*.log

      # These logs are for the process level synthetic ghost injection and are not normally seen. Only seen when the
      # INJECT_POST_THREAD_GHOST_REAL_PUBLIC_IPS ENV variable is enabled
      - logs/real_process_ghost_ip_*.log
      - logs/ghost_pool.json  ## this file is generated early in module2 main(). This file is used for the pop stack read for the INJECT_POST_THREAD_GHOST_REAL_PUBLIC_IPSA code
      
      
      # These are for the process level stats that are generated from resurrection monitor function in module2
      - logs/statistics/process_stats_*.json

      # These are the aggregate main level stats that are derived from the process level stats
      - logs/statistics/aggregate_process_stats.json

      # These are the aggregate process stats witht the gatekeeper stats as well from module2d
      - logs/statistics/aggregate_process_stats_gatekeeper_module2d.json

      # These are the nodes that get stuck at AWS orchestration layer (for example, status1/2) and are stopped and started and still 
      # do not come up. These are not included in the golden ip list and will not show up even as ghosts
      - logs/orchestration_layer_rehydration_failed_nodes.json

      # Phase3 log files 
      - logs/command_plan.json  # module2 command set of wrapped native_commands from module2 used in phase3 module2e
      - logs/resurrection_module2e_registry.json  # module2e phase3 registry with modified tags and command set added
      - logs/statistics/aggregate_selected_for_resurrection_stats_module2e.json  # module2e phase3 thread selected for resurrection stats
      - logs/resurrection_module2e_registry_rebooted.json  # module2e phase3 registry with post reboot flags and to be used in module2f

      - logs/module2f_resurrection_results.json   # module2f resurrection results
      - logs/statistics/aggregate_resurrected_node_stats_module2f.json  # module2f phase2 thread resurrection node results





    expire_in: 1 week

  allow_failure: true
  only:
    - main


    #script:
    #  - mkdir -p logs
    #  - docker run --rm --env-file .env -v $CI_PROJECT_DIR/logs:/aws_EC2/logs $CI_REGISTRY_IMAGE:latest
    #  - echo "Contents of logs directory after container run:"
    #  - ls -l logs/
    #  - cat logs/benchmark_*.log > logs/benchmark_combined.log
    #
    #artifacts:
    #  paths:
    #    - logs/
    #    - logs/benchmark_combined.log
    #  expire_in: 1 week
    #
    #allow_failure: true
    #only:
    #  - main
    #



cleanup:
  stage: cleanup
  script:
    - docker rmi $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA $CI_REGISTRY_IMAGE:latest -f
  when: always
