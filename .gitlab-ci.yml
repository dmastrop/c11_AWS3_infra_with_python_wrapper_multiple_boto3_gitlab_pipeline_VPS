stages:
  #  - lint
  - build
  - push
  - deploy
  - cleanup

# add the lint stage to verify the code structure and syntax. This will abort the pipeline if there are problems

    
# this lint stage is non-blocking and will not abort, but just report the INFO to the gitlab console


    
build:
  stage: build
  script:
    # this one is for running Dockerfile which is python wrapper method (and it ai parallelized now). It is 
    # a manual script running of the python files natively in parallel (not using multi-threading python class)
    # using a file range(array list) function
    #- docker build -t $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE:latest .
    
    # this one is for running Dockerfile_python_mod_NO_but_serial, the python modularization setup without parallelization
    #- docker build --file Dockerfile_python_mod_NO_but_serial -t $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE:latest .

    # this one is for running Dockerfile_python_mod_multi_threaded, modularization with multi-threading
    #- docker build --file Dockerfile_python_mod_multi_threaded -t $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE:latest .
  
    # this one is for running Dockerfile_python_mod_multi_processing, modularization with mutli-processing
    - docker build --file Dockerfile_python_mod_multi_processing -t $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE:latest .


push:
  stage: push
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker push $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA
    - docker push $CI_REGISTRY_IMAGE:latest


      # default instance_type is t2.micro. Test out a t3.small for performance installation issues.   
      # 30 processes(desired_count)  x chunk_size=2 â†’ 60 EC2 instances total so set max and min count to 60 (example)   
deploy:
  stage: deploy
  variables:
    PID_JSON_DUMPS: "true"  
    # this is a gating env VAR for module2 if I need to disable the process level resurrection candidate
    # or ghost json artifact files during hyper-scalling
  
  before_script:
    - echo 'AWS_ACCESS_KEY_ID='${AWS_ACCESS_KEY_ID} >> .env
    - echo 'AWS_SECRET_ACCESS_KEY='${AWS_SECRET_ACCESS_KEY} >> .env
    - echo 'region_name=us-east-1' >> .env
    - echo 'image_id=ami-0f9de6e2d2f067fca' >> .env
    - echo 'instance_type=t2.micro' >> .env
    - echo 'key_name=generic_keypair_for_python_testing' >> .env
    - echo 'min_count=256' >> .env
    - echo 'max_count=256' >> .env
    - echo 'AWS_PEM_KEY='${AWS_PEM_KEY} >> .env
    - echo 'DB_USERNAME='${DB_USERNAME} >> .env
    - echo 'DB_PASSWORD='${DB_PASSWORD} >> .env
    - echo 'PID_JSON_DUMPS='${PID_JSON_DUMPS} >> .env  # see above. Gating for the json ghost and res candidate files.  



      ## NOTE: To turn off dumps in specific pipelines or environments:Go to **Settings > CI/CD > Variables in the project
      ## Define `PID_JSON_DUMPS` with value `false` (masked/protected as needed).
      ## This value will override the one above in this file. 


      #      # use this for most of the Dockerfiles. The multiprocessing Dockerfile is collecting logs from the container for
      #      # benchmarking so use the one below for the multiprocessing Dockerfile    
      #  script:
      #    - docker run --rm --env-file .env $CI_REGISTRY_IMAGE:latest
      #  allow_failure: true
      #  # this will keep the pipeline going to cleanup stage even if the above python script  fails
      #  only:
      #    - main
      #




      # use this one for the multiprocessing Dockerfile. This mounts to the WORKDIR on the container so that
      # the gitlab pipeline can get the artifact from the $CI_PROJECT_DIR of the gitlab repo
      # The artifact path is specified below relative to the gitlab project directory
      # Refer to teh python module2 to see the per process logging setup to benchmark the multi-threading operations
      # in each process
      #
  script:
    - mkdir -p logs
    - docker run --rm --env-file .env -v $CI_PROJECT_DIR/logs:/aws_EC2/logs $CI_REGISTRY_IMAGE:latest
    - echo "Contents of logs directory after container run:"
    - ls -l logs/
    - echo "Last 10 lines of MAIN logs:"
    - cat logs/main_*.log | tail -10

    - |
      for f in logs/benchmark_[0-9]*.log; do
      # bad bug creating duplicated entires from benchmark_combined_runtime.log in patch7 in benchmark_combined.log
      #for f in logs/benchmark_*.log; do
        echo "===== $f =====" >> logs/benchmark_combined.log
        cat "$f" >> logs/benchmark_combined.log
        echo "" >> logs/benchmark_combined.log
      done


  artifacts:
    paths:
      - logs/
      - logs/main_*.log  # top elve orchestration level stats for entire execution
      - logs/benchmark_*.log  # process level orchestration level stats logs 
      - logs/benchmark_combined.log  # this is the orchestration level logging of all the benchmark_*.logs (process level stats). This is created post execution in gitlab-ci.yml (seea above)

      - logs/benchmark_combined_runtime.log  # this is the python run time created benchmark_combined stats log created from the benchmark_*.log pid logs that are created during run time.  
      
      - logs/benchmark_ips_artifact.log  # this is the GOLD standard by which to compare the runtime registires to for missing, failed, successful and total (in addtion to scanning the tags/status)

      - logs/total_registry_ips_artifact.log  # stats created from the final_aggregate_execution_run_registry.json registry. THese are the actual registry entries, not stats. Same for the next 3 logs as well.
      - logs/missing_registry_ips_artifact.log
      - logs/successful_registry_ips_artifact.log
      - logs/failed_registry_ips_artifact.log
      
      - logs/patch7_summary_*.log # this is for the per process logging in resurrection_monitor_patch7c. This is completely separate from the orchestration level logging and this is used for forensics and debugging.
      
        # these are process level logs from the resurrection_montior_patch7c(). These are actual registry entries for resurrection candidates for phase3 implementation. Ghosts are missing when compared to GOLD standard and do not have standard failure tags  
      - logs/resurrection_candidates_registry_*.json
      - logs/resurrection_ghost_missing_*.json
     
      # resurrection_monitor pid based snapshot for all registry values. This has been replaced with final_aggregate_execution_run_registry.json
      #- logs/resurrection_process_registry_snapshot_*.json
      
      # write-to-disk aggregator json files. The log files above are derived from these. This has all registry values for the
      # entire execution run. This replaces the snapshot json log above that was formerly done in resurrection_monitor
      # This log below is done in main()
      - logs/final_aggregate_execution_run_registry.json
      
        # per process registry logs from tomcat_worker(). These are used to create the final_registry and summary and these are then used to create the aggregate registry for the execution run : logs/final_aggregate_execution_run_registry.json
      - logs/process_registry_*.json  
        
        
        
        #- logs/resurrection_registry_log_*.json
        #- logs/resurrection_ghost_log_*.json
          
    expire_in: 1 week

  allow_failure: true
  only:
    - main


    #script:
    #  - mkdir -p logs
    #  - docker run --rm --env-file .env -v $CI_PROJECT_DIR/logs:/aws_EC2/logs $CI_REGISTRY_IMAGE:latest
    #  - echo "Contents of logs directory after container run:"
    #  - ls -l logs/
    #  - cat logs/benchmark_*.log > logs/benchmark_combined.log
    #
    #artifacts:
    #  paths:
    #    - logs/
    #    - logs/benchmark_combined.log
    #  expire_in: 1 week
    #
    #allow_failure: true
    #only:
    #  - main
    #



cleanup:
  stage: cleanup
  script:
    - docker rmi $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA $CI_REGISTRY_IMAGE:latest -f
  when: always
