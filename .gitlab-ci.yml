stages:
  #  - lint
  - build
  - push
  - deploy
  - cleanup

# add the lint stage to verify the code structure and syntax. This will abort the pipeline if there are problems

    
# this lint stage is non-blocking and will not abort, but just report the INFO to the gitlab console


    
build:
  stage: build
  script:
    # this one is for running Dockerfile which is python wrapper method (and it ai parallelized now). It is 
    # a manual script running of the python files natively in parallel (not using multi-threading python class)
    # using a file range(array list) function
    #- docker build -t $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE:latest .
    
    # this one is for running Dockerfile_python_mod_NO_but_serial, the python modularization setup without parallelization
    #- docker build --file Dockerfile_python_mod_NO_but_serial -t $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE:latest .

    # this one is for running Dockerfile_python_mod_multi_threaded, modularization with multi-threading
    #- docker build --file Dockerfile_python_mod_multi_threaded -t $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE:latest .
  
    # this one is for running Dockerfile_python_mod_multi_processing, modularization with mutli-processing
    - docker build --file Dockerfile_python_mod_multi_processing -t $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE:latest .


push:
  stage: push
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker push $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA
    - docker push $CI_REGISTRY_IMAGE:latest


      # default instance_type is t2.micro. Test out a t3.small for performance installation issues.   
      # 30 processes(desired_count)  x chunk_size=2 → 60 EC2 instances total so set max and min count to 60 (example)   
deploy:
  stage: deploy
  variables:
    PID_JSON_DUMPS: "false"  
    # this is a gating env VAR for module2 if I need to disable the process level resurrection candidate
    # or ghost json artifact files during hyper-scalling
 
    ##### Synthetic thread failures in install_tomcat ########
    FORCE_TOMCAT_FAIL: "false"  # ← Inject synthetic failure for testing (futures crash). The synthetic futures crash code is in instalL_tomcat. Use "1" or "true" to inject and "false" or "0" to not inject. This one is right before the for idx.  These FORCE_TOMCAT crashes do not exercise actual module2c scanning code. See below for that ENV variable.

    FORCE_TOMCAT_FAIL_IDX1: "false"

    FORCE_TOMCAT_FAIL_POSTINSTALL: "false"

    FORCE_TOMCAT_FAIL_PRE_SSH: "false"

    INJECT_SYNTHETIC_GHOST1: "false"  # Inject a synthetic ghost into the aggregate_gold_ips list in main() in module 2. Module2b will pick this up in aggregate_ghost_summary.log  and find that there is a ghost that needs to be analyzed in the logs. 1.1.1.1

    INJECT_SYNTHETIC_GHOST2: "false"  # 1.1.1.2
    INJECT_SYNTHETIC_GHOST3: "false"  # 1.1.1.3
    INJECT_SYNTHETIC_GHOST4: "false"  # 1.1.1.4
    INJECT_SYNTHETIC_GHOST5: "false"  # 1.1.1.5
    INJECT_SYNTHETIC_GHOST6: "false"  # 1.1.1.6
    INJECT_SYNTHETIC_GHOST7: "false"  # 1.1.1.7
    INJECT_SYNTHETIC_GHOST8: "false"  # 1.1.1.8
    INJECT_SYNTHETIC_GHOST9: "false"  # 1.1.1.9
    INJECT_SYNTHETIC_GHOST10: "false"  # 1.1.1.10


    FORCE_TOMCAT_FAIL_POSTINSTALL_REAL_TAG: "true"  # post install futures crash with real tagging of module2c. This actually uses the
      # post gitlab console logs sanning of module2c to determine if there is a futures crash that had all commands executed 
      # successfully. In this case an additional tag has to be added that indicates that installation is successful.


    INJECT_PROCESS_GHOSTS: "false" # this is injection of ghosts at the process chunk level which main() will then pass to all the
      # downstream modules like tomcat_worker resurrection_monitor_patch8 threaded_install and install_tomcat so that detect_ghosts
      # helper function can be tested. This is a more realistic ghost injection. This does not work because it requires a synthetic
      # InstanceId as well for downstream code, and that synthetic InstanceId causes a futures crash (install_failed) instead of a
      # ghost.  The code for this has been commented out.   Use the flag below
      
    INJECT_POST_THREAD_GHOSTS: "true"  # this injection is in tomcat_worker between the process_registry run_test call to 
      # threaded_install which establishes the process_registry for the process (seen_ips) and the call to 
      # resurrection_monitor_patch8. The instance_info variable is mutated in between the two with the ghost injection. This 
      # creates delta between seen_ips and golden ips which are missing_ips or ghosts, as evalluated by the helper fuction 
      # detect_ghosts. Once this happens detect_ghosts prints the PID and the ghost ip and module2b picks this up in the 
      # gitlab console log scan, and it can then create the aggregate_ghost_deteail.json ghost entry which will then be 
      # synthetically modified to registry_entry format in module2d so that it can be processed by the gatekeeper.


  before_script:
    - echo 'AWS_ACCESS_KEY_ID='${AWS_ACCESS_KEY_ID} >> .env
    - echo 'AWS_SECRET_ACCESS_KEY='${AWS_SECRET_ACCESS_KEY} >> .env
    - echo 'region_name=us-east-1' >> .env
    - echo 'image_id=ami-0f9de6e2d2f067fca' >> .env
    - echo 'instance_type=t2.micro' >> .env
    - echo 'key_name=generic_keypair_for_python_testing' >> .env
    - echo 'min_count=16' >> .env
    - echo 'max_count=16' >> .env
    - echo 'AWS_PEM_KEY='${AWS_PEM_KEY} >> .env
    - echo 'DB_USERNAME='${DB_USERNAME} >> .env
    - echo 'DB_PASSWORD='${DB_PASSWORD} >> .env
    
    - echo 'PID_JSON_DUMPS='${PID_JSON_DUMPS} >> .env  # see above. Gating for the json ghost and res candidate files.  
    
    - echo 'FORCE_TOMCAT_FAIL='${FORCE_TOMCAT_FAIL} >> .env # This is to inject a futures crash in install_tomcat
    - echo 'FORCE_TOMCAT_FAIL_IDX1='${FORCE_TOMCAT_FAIL_IDX1} >> .env # futures crash after first command executes
    - echo 'FORCE_TOMCAT_FAIL_POSTINSTALL='${FORCE_TOMCAT_FAIL_POSTINSTALL} >> .env  # futures crash after installation
    - echo 'FORCE_TOMCAT_FAIL_PRE_SSH='${FORCE_TOMCAT_FAIL_PRE_SSH} >> .env  # futures crash before SSH initiated
    
    - echo 'INJECT_SYNTHETIC_GHOST1='${INJECT_SYNTHETIC_GHOST1} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST2='${INJECT_SYNTHETIC_GHOST2} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST3='${INJECT_SYNTHETIC_GHOST3} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST4='${INJECT_SYNTHETIC_GHOST4} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST5='${INJECT_SYNTHETIC_GHOST5} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST6='${INJECT_SYNTHETIC_GHOST6} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST7='${INJECT_SYNTHETIC_GHOST7} >> .env  # inject synthetic ghost into aggregate_gold_ips

    - echo 'INJECT_SYNTHETIC_GHOST8='${INJECT_SYNTHETIC_GHOST8} >> .env  # inject synthetic ghost into aggregate_gold_ips
    
    - echo 'INJECT_SYNTHETIC_GHOST9='${INJECT_SYNTHETIC_GHOST9} >> .env  # inject synthetic ghost into aggregate_gold_ips
    
    - echo 'INJECT_SYNTHETIC_GHOST10='${INJECT_SYNTHETIC_GHOST10} >> .env  # inject synthetic ghost into aggregate_gold_ips

  
    
    - echo 'FORCE_TOMCAT_FAIL_POSTINSTALL_REAL_TAG='${FORCE_TOMCAT_FAIL_POSTINSTALL_REAL_TAG} >> .env  # futures crash after installation with real tagging using module2c


    - echo 'INJECT_PROCESS_GHOSTS='${INJECT_PROCESS_GHOSTS} >> .env  # inject synthetic ghost at the process chunk level. This code does not work well as noted above.


    - echo 'INJECT_POST_THREAD_GHOSTS='${INJECT_POST_THREAD_GHOSTS} >> .env  # inject synthetic ghost at the process level in tomcat_worker between the call to run_test/threaded_install for the process_registry AND the call to the resurrection_monitor_patch8. Mutate theinstance_info variable which maps to assigned_ips in the resurrection_monitor function.




       
      ## NOTE: To turn off dumps in specific pipelines or environments:Go to **Settings > CI/CD > Variables in the project
      ## Define `PID_JSON_DUMPS` with value `false` (masked/protected as needed).
      ## This value will override the one above in this file. 


      #      # use this for most of the Dockerfiles. The multiprocessing Dockerfile is collecting logs from the container for
      #      # benchmarking so use the one below for the multiprocessing Dockerfile    
      #  script:
      #    - docker run --rm --env-file .env $CI_REGISTRY_IMAGE:latest
      #  allow_failure: true
      #  # this will keep the pipeline going to cleanup stage even if the above python script  fails
      #  only:
      #    - main
      #




      # use this one for the multiprocessing Dockerfile. This mounts to the WORKDIR on the container so that
      # the gitlab pipeline can get the artifact from the $CI_PROJECT_DIR of the gitlab repo
      # The artifact path is specified below relative to the gitlab project directory
      # Refer to teh python module2 to see the per process logging setup to benchmark the multi-threading operations
      # in each process
      #
  script:
    - mkdir -p logs
    #- docker run --rm --env-file .env -v $CI_PROJECT_DIR/logs:/aws_EC2/logs $CI_REGISTRY_IMAGE:latest
    # add the tee to get all the gitlab console output into a log file in the gitlab artfacts:
    - docker run --rm --env-file .env -v $CI_PROJECT_DIR/logs:/aws_EC2/logs $CI_REGISTRY_IMAGE:latest | tee logs/gitlab_full_run.log  
    - echo "Contents of logs directory after container run:"
    - ls -l logs/
    - echo "Last 10 lines of MAIN logs:"
    - cat logs/main_*.log | tail -10

    - |
      for f in logs/benchmark_[0-9]*.log; do
      # bad bug creating duplicated entires from benchmark_combined_runtime.log in patch7 in benchmark_combined.log
      #for f in logs/benchmark_*.log; do
        echo "===== $f =====" >> logs/benchmark_combined.log
        cat "$f" >> logs/benchmark_combined.log
        echo "" >> logs/benchmark_combined.log
      done


  artifacts:
    paths:
      - logs/
      - logs/main_*.log  # top elve orchestration level stats for entire execution
      - logs/benchmark_*.log  # process level orchestration level stats logs 
      - logs/benchmark_combined.log  # this is the orchestration level logging of all the benchmark_*.logs (process level stats). This is created post execution in gitlab-ci.yml (seea above)

      - logs/benchmark_combined_runtime.log  # this is the python run time created benchmark_combined stats log created from the benchmark_*.log pid logs that are created during run time.  
      
      - logs/benchmark_ips_artifact.log  # this a list of benchmark ips from the threads in the benchmark_combined_runtime.log

      - logs/total_registry_ips_artifact.log  # stats created from the final_aggregate_execution_run_registry.json registry. THese are the actual registry entries, not stats. Same for the next 3 logs as well.
      - logs/missing_registry_ips_artifact.log
      - logs/successful_registry_ips_artifact.log
      - logs/failed_registry_ips_artifact.log
      
      - logs/patch7_summary_*.log # this is for the per process logging in resurrection_monitor_patch7c. This is completely separate from the orchestration level logging and this is used for forensics and debugging.
      
        # these are process level logs from the resurrection_montior_patch7c(). These are actual registry entries for resurrection candidates for phase3 implementation. Ghosts are missing when compared to GOLD standard and do not have standard failure tags  
      - logs/resurrection_candidates_registry_*.json
      - logs/resurrection_ghost_missing_*.json
      - logs/resurrection_untraceable_registry_entries_*.json  
     
      # resurrection_monitor pid based snapshot for all registry values. This has been replaced with final_aggregate_execution_run_registry.json
      #- logs/resurrection_process_registry_snapshot_*.json
      
      # write-to-disk aggregator json files. The log files above are derived from these. This has all registry values for the
      # entire execution run. This replaces the snapshot json log above that was formerly done in resurrection_monitor
      # This log below is done in main()
      - logs/final_aggregate_execution_run_registry.json
      
      # per process registry logs from tomcat_worker(). These are used to create the final_registry and summary and these are then used to create the aggregate registry for the execution run : logs/final_aggregate_execution_run_registry.json
      - logs/process_registry_*.json  
        
      # This is the log file for the GOLD aggreagate IP EC2 list from the AWS control plane operations. This will be used for ghost detection at aggregate level. This is derived from "chunks" the pre-processing  of the IPs for the multi-processing engine.
      - logs/aggregate_chunk_gold_ip_list.log  
       
      # This is an aggregate level ghost list of ips from the GOLD standard comparison list above

      - logs/aggregate_ghost_summary.log  

      # These are the complete gitlab console logs from the docker run tee above. These will be used for post ghost analysis tagging.
      - logs/gitlab_full_run.log    
   
      # module2b post ghost analysis artifact log file
      - logs/aggregate_ghost_detail.json 

      # module2c post aggregate registry analysis artifact log file
      - logs/final_aggregate_execution_run_registry_module2c.json

      # module2d post aggregate registry that has been processed by the resurrection_gatekeeper
      - logs/final_aggregate_execution_run_registry_module2d.json

      # module2d aggregate_ghost_detail that has been transformed into synthetic registry (for res gatekeeper processing)
      - logs/aggregate_ghost_detail_synthetic_registry.json

      # module2d post aggregate ghost detail that has been processed by the resurrection_gatekeeper    
      - logs/aggregate_ghost_detail_module2d.json

      # module2d consolildated aggregate_ghost_detail_module2d.jsn + final_aggregate_execution_run_registry_module2d.json for
      # Phase3 resurrection and requeing code
      - logs/resurrection_gatekeeper_final_registry_module2d.json   


      # These logs are for the process level synthetic ghost injection and are not normally seen. Only seen when the
      # INJECT_POST_THREAD_GHOST ENV variable is enabled
      - logs/synthetic_process_ghost_ip_pid_*.log
        
    expire_in: 1 week

  allow_failure: true
  only:
    - main


    #script:
    #  - mkdir -p logs
    #  - docker run --rm --env-file .env -v $CI_PROJECT_DIR/logs:/aws_EC2/logs $CI_REGISTRY_IMAGE:latest
    #  - echo "Contents of logs directory after container run:"
    #  - ls -l logs/
    #  - cat logs/benchmark_*.log > logs/benchmark_combined.log
    #
    #artifacts:
    #  paths:
    #    - logs/
    #    - logs/benchmark_combined.log
    #  expire_in: 1 week
    #
    #allow_failure: true
    #only:
    #  - main
    #



cleanup:
  stage: cleanup
  script:
    - docker rmi $CI_REGISTRY_IMAGE:$CI_PIPELINE_IID-$CI_COMMIT_SHORT_SHA $CI_REGISTRY_IMAGE:latest -f
  when: always
